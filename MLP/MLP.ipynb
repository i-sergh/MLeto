{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82ef5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # добавляет массивы и математику\n",
    "import sys \n",
    "\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt # для графиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2613afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2af725a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1214590843366 1.8640351295471191\n"
     ]
    }
   ],
   "source": [
    "last = time.time()\n",
    "\n",
    "\n",
    "mul = 0\n",
    "for ai, bi in zip(a, b):\n",
    "    mul+= ai* bi \n",
    "\n",
    "print(mul ,time.time() - last)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8182081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-884901402 1.671391248703003\n"
     ]
    }
   ],
   "source": [
    "last = time.time()\n",
    "\n",
    "ma = np.array(a)\n",
    "mb = np.array(b)\n",
    "\n",
    "mul = np.dot(ma, mb)\n",
    "print(mul ,time.time() - last)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2ce8ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__ (self, n_hidden=30, l2=0, epochs=100, eta = 0.001, shuffle=True, minibatch_size=1, seed=42):\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2 = l2 \n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatch_size = minibatch_size\n",
    "    \n",
    "    def _onehot (self, y, n_classes):\n",
    "        onehot = np.zeros( (n_classes, y.shape[0] ) )\n",
    "        \n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            onehot[val, idx] = 1\n",
    "        \n",
    "        return onehot.T\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        return 1./(1. + np.exp(-np.clip(z, -250, 250)))\n",
    "    \n",
    "    def _forward(self, X):\n",
    "        # гигасумма для скрытого слоя\n",
    "        z_h = np.dot(X, self.w_h) + self.b_h\n",
    "        # активация\n",
    "        a_h = self._sigmoid(z_h)\n",
    "        # гигасумма для слоя dsвыходного\n",
    "        z_out = np.dot(a_h, self.w_out ) + self.b_out\n",
    "        # активация активация выходного слоя\n",
    "        a_out = self._sigmoid(z_out)\n",
    "        \n",
    "        return z_h, a_h, z_out, a_out\n",
    "    \n",
    "    def _compute_cost (self, y_enc, output):\n",
    "        L2_term = (self.l2 * (np.sum(self.w_h ** 2) + np.sum(self.w_out ** 2) ) )\n",
    "        \n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1 - y_enc) * np.log(1 - output)\n",
    "        \n",
    "        cost = np.sum(term1 - term2) + L2_term \n",
    "        return cost\n",
    "    \n",
    "    def predict (self, X):\n",
    "        z_h, a_h, z_out, a_out = self._forward(X)\n",
    "        \n",
    "        y_pred = np.argmax(z_out, axis=1)\n",
    "        return y_pred\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        # кол-во меток (кол-во выходов)\n",
    "        n_output = np.unique(y_train).shape[0]\n",
    "        # кол-во признаков\n",
    "        n_features = X_train.shape[1]\n",
    "        \n",
    "        \n",
    "        self.b_h = np.zeros(self.n_hidden ) # warum zero ? किन\n",
    "        self.w_h = self.random.normal( loc = 0.0, scale=0.1, size=(n_features, self.n_hidden ) )\n",
    "        \n",
    "        self.b_out = np.zeros(n_output)\n",
    "        self.w_out = self.random.normal(loc=0.0, scale=0.1, size=(self.n_hidden, n_output))\n",
    "        \n",
    "        # для того чтобы красиво принтить\n",
    "        epoh_strlen = len(str(self.epochs))\n",
    "        \n",
    "        y_train_enc = self._onehot(y_train, n_output)\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "            \n",
    "            if self.shuffle:\n",
    "                self.random.shuffle(indices)\n",
    "            \n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size + 1, self.minibatch_size ):\n",
    "                \n",
    "                batch_idx = indices[start_idx: start_idx + self.minibatch_size ]\n",
    "                \n",
    "                # forvard \n",
    "                z_h, a_h, z_out, a_out = self._forvard(X_train[batch_idx])\n",
    "                \n",
    "                # обратное распространение\n",
    "                # backward \n",
    "                \n",
    "                sigma_out = a_out - y_train_enc[batch_idx]\n",
    "                \n",
    "                sigmoid_derivative_h = a_h * (1 - a_h) # warum\n",
    "                \n",
    "                sigma_h = (np.dot(sigma_out, self.w_out.T) * sigmoid_derivative_h)\n",
    "                \n",
    "                grad_w_h = np.dot(X_train[batch_idx].T, sigma_h)\n",
    "                grad_b_h = np.sum(sigma_h, axis=0)\n",
    "                \n",
    "                grad_w_out = np.dot(a_h.T, sigma_out)\n",
    "                grad_b_out = np.sum(sigma_out, axis=0)\n",
    "                \n",
    "                # обновление весов\n",
    "                \n",
    "                delta_w_h = (grad_w_h + self.l2 * self.w_h)\n",
    "                delta_b_h = grad_b_h\n",
    "                \n",
    "                self.w_h -= self.eta * delta_w_h\n",
    "                self.b_h -= self.eta * delta_b_h\n",
    "                \n",
    "                ####\n",
    "                delta_w_out = (grad_w_out + self.l2 * self.w_out)\n",
    "                delta_b_out = grad_b_out\n",
    "                \n",
    "                self.w_out -= self.eta * delta_w_out\n",
    "                self.b_out -= self.eta * delta_b_out\n",
    "                \n",
    "                \n",
    "                # Оценка\n",
    "                \n",
    "                z_h, a_h, z_out, a_out = self._forward(X_train)\n",
    "                \n",
    "                cost =self._compute_cost (y_enc=y_train_enc, output=a_out)\n",
    "                \n",
    "                y_train_pred = self.predict(X_train)\n",
    "                y_valid_pred = self.predict(X_valid)\n",
    "                \n",
    "                train_acc = (np.sum(y_train == y_train_pred)).astype(np.float)/X_train.shape[0]\n",
    "                valid_acc = (np.sum(y_valid == y_valid_pred)).astype(np.float)/X_valid.shape[0]\n",
    "                \n",
    "                print( '\\r%0*d/%d | Издержки: %.2f | Правильность при обучении/при проверке: %.2f%%/%.2f%%'%\n",
    "                       (epoch_strlen, i+1, sepf.epochs, cost, train_acc*100, valid_acc*100))\n",
    "                \n",
    "                \n",
    "                self.eval_['cost'].append(cost)\n",
    "                self.eval_['train_acc'].append(train_acc)\n",
    "                self.eval_['valid_acc'].append(valid_acc)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ab797b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(n_hidden=100,\n",
    "         l2=0.01,\n",
    "         epochs=200,\n",
    "         eta=0.0005,\n",
    "         minibatch_size=100,\n",
    "         shuffle=True,\n",
    "         seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9024a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4c08a11",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (960309096.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [24]\u001b[1;36m\u001b[0m\n\u001b[1;33m    path = 'C:\\Users\\admin\\Desktop\\toGit\\mlp\\MLeto\\MLP\\data_sets\\train-labels-idx1-ubyte\\\\'\u001b[0m\n\u001b[1;37m                                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\Users\\admin\\Desktop\\toGit\\mlp\\MLeto\\MLP\\data_sets\\train-labels-idx1-ubyte\\\\'\n",
    "labels_path = 'train-labels-idx1-ubyte'\n",
    "labels_path = os.path.join(path, labels_path )\n",
    "with open(labels_path, 'rb') as lbpath:\n",
    "    magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "    \n",
    "    labels = np.fromfile(lbpath, dtype=np.uint8())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1338ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c63c7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "plt.matshow(digits.images[42],cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2224af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
